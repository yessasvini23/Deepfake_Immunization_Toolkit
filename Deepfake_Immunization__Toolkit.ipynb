{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Deepfake Immunization Toolkit\n",
        "# A comprehensive system for deepfake detection, user training, and content verification\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import gradio as gr\n",
        "import hashlib\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    packages = [\n",
        "        'torch', 'torchvision', 'opencv-python', 'gradio',\n",
        "        'matplotlib', 'sklearn', 'pillow', 'numpy'\n",
        "    ]\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package.replace('-', '_'))\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "install_packages()\n",
        "\n",
        "class SimpleBlockchain:\n",
        "    \"\"\"Simplified blockchain for content verification\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.chain = []\n",
        "        self.create_genesis_block()\n",
        "\n",
        "    def create_genesis_block(self):\n",
        "        genesis_block = {\n",
        "            'index': 0,\n",
        "            'timestamp': time.time(),\n",
        "            'data': 'Genesis Block',\n",
        "            'previous_hash': '0',\n",
        "            'hash': self.calculate_hash(0, time.time(), 'Genesis Block', '0')\n",
        "        }\n",
        "        self.chain.append(genesis_block)\n",
        "\n",
        "    def calculate_hash(self, index, timestamp, data, previous_hash):\n",
        "        value = str(index) + str(timestamp) + str(data) + str(previous_hash)\n",
        "        return hashlib.sha256(value.encode('utf-8')).hexdigest()\n",
        "\n",
        "    def get_latest_block(self):\n",
        "        return self.chain[-1]\n",
        "\n",
        "    def add_block(self, data):\n",
        "        latest_block = self.get_latest_block()\n",
        "        new_block = {\n",
        "            'index': latest_block['index'] + 1,\n",
        "            'timestamp': time.time(),\n",
        "            'data': data,\n",
        "            'previous_hash': latest_block['hash'],\n",
        "            'hash': None\n",
        "        }\n",
        "        new_block['hash'] = self.calculate_hash(\n",
        "            new_block['index'],\n",
        "            new_block['timestamp'],\n",
        "            new_block['data'],\n",
        "            new_block['previous_hash']\n",
        "        )\n",
        "        self.chain.append(new_block)\n",
        "        return new_block['hash']\n",
        "\n",
        "    def verify_content(self, content_hash):\n",
        "        for block in self.chain:\n",
        "            if isinstance(block['data'], dict) and block['data'].get('content_hash') == content_hash:\n",
        "                return True, block\n",
        "        return False, None\n",
        "\n",
        "class DeepfakeDetector(nn.Module):\n",
        "    \"\"\"Enhanced CNN for deepfake detection\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DeepfakeDetector, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Adaptive pooling to handle different input sizes\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 2)  # Binary classification: real/fake\n",
        "\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm4 = nn.BatchNorm2d(256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.batch_norm1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.batch_norm2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.batch_norm3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.batch_norm4(self.conv4(x))))\n",
        "\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "class FederatedLearning:\n",
        "    \"\"\"Simplified federated learning for privacy-preserving model updates\"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.global_model = model\n",
        "        self.client_updates = []\n",
        "        self.round_number = 0\n",
        "\n",
        "    def add_client_update(self, model_state_dict, data_size):\n",
        "        \"\"\"Add a client's model update\"\"\"\n",
        "        self.client_updates.append({\n",
        "            'state_dict': model_state_dict,\n",
        "            'data_size': data_size,\n",
        "            'timestamp': time.time()\n",
        "        })\n",
        "\n",
        "    def aggregate_updates(self):\n",
        "        \"\"\"Aggregate client updates using weighted averaging\"\"\"\n",
        "        if not self.client_updates:\n",
        "            return\n",
        "\n",
        "        # Calculate total data size\n",
        "        total_data_size = sum(update['data_size'] for update in self.client_updates)\n",
        "\n",
        "        # Initialize aggregated parameters\n",
        "        aggregated_params = {}\n",
        "\n",
        "        # Get parameter names from the first update\n",
        "        param_names = list(self.client_updates[0]['state_dict'].keys())\n",
        "\n",
        "        for param_name in param_names:\n",
        "            # Weighted average of parameters\n",
        "            weighted_sum = torch.zeros_like(self.client_updates[0]['state_dict'][param_name])\n",
        "\n",
        "            for update in self.client_updates:\n",
        "                weight = update['data_size'] / total_data_size\n",
        "                weighted_sum += weight * update['state_dict'][param_name]\n",
        "\n",
        "            aggregated_params[param_name] = weighted_sum\n",
        "\n",
        "        # Update global model\n",
        "        self.global_model.load_state_dict(aggregated_params)\n",
        "\n",
        "        # Clear client updates\n",
        "        self.client_updates = []\n",
        "        self.round_number += 1\n",
        "\n",
        "        return f\"Federated learning round {self.round_number} completed with {len(self.client_updates)} clients\"\n",
        "\n",
        "class DeepfakeImmunizationToolkit:\n",
        "    \"\"\"Main toolkit class combining all components\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.detector = DeepfakeDetector()\n",
        "        self.blockchain = SimpleBlockchain()\n",
        "        self.federated_learning = FederatedLearning(self.detector)\n",
        "        self.training_data = []\n",
        "        self.user_scores = {'correct': 0, 'total': 0}\n",
        "\n",
        "        # Initialize with some training\n",
        "        self._initialize_model()\n",
        "\n",
        "    def _initialize_model(self):\n",
        "        \"\"\"Initialize the model with some basic training\"\"\"\n",
        "        # Create dummy training data\n",
        "        batch_size = 10\n",
        "        real_data = torch.randn(batch_size, 3, 224, 224)\n",
        "        fake_data = torch.randn(batch_size, 3, 224, 224) * 0.8  # Slightly different distribution\n",
        "\n",
        "        X = torch.cat([real_data, fake_data], dim=0)\n",
        "        y = torch.cat([torch.zeros(batch_size), torch.ones(batch_size)], dim=0).long()\n",
        "\n",
        "        # Simple training loop\n",
        "        optimizer = torch.optim.Adam(self.detector.parameters(), lr=0.001)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.detector.train()\n",
        "        for epoch in range(5):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.detector(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        self.detector.eval()\n",
        "\n",
        "    def preprocess_image(self, image):\n",
        "        \"\"\"Preprocess image for the model\"\"\"\n",
        "        if isinstance(image, np.ndarray):\n",
        "            image = Image.fromarray(image)\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        return transform(image).unsqueeze(0)\n",
        "\n",
        "    def detect_deepfake(self, image):\n",
        "        \"\"\"Detect if an image is a deepfake\"\"\"\n",
        "        try:\n",
        "            processed_image = self.preprocess_image(image)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.detector(processed_image)\n",
        "                probabilities = outputs[0]\n",
        "\n",
        "                is_fake = probabilities[1].item() > 0.5\n",
        "                confidence = max(probabilities).item()\n",
        "\n",
        "                # Additional heuristic checks\n",
        "                heuristic_score = self._heuristic_analysis(image)\n",
        "\n",
        "                # Combine model prediction with heuristics\n",
        "                final_confidence = (confidence + heuristic_score) / 2\n",
        "\n",
        "                return {\n",
        "                    'is_deepfake': is_fake,\n",
        "                    'confidence': final_confidence,\n",
        "                    'model_confidence': confidence,\n",
        "                    'heuristic_score': heuristic_score,\n",
        "                    'probabilities': {\n",
        "                        'real': probabilities[0].item(),\n",
        "                        'fake': probabilities[1].item()\n",
        "                    }\n",
        "                }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'is_deepfake': False,\n",
        "                'confidence': 0.5,\n",
        "                'error': str(e),\n",
        "                'probabilities': {'real': 0.5, 'fake': 0.5}\n",
        "            }\n",
        "\n",
        "    def _heuristic_analysis(self, image):\n",
        "        \"\"\"Simple heuristic analysis for deepfake detection\"\"\"\n",
        "        try:\n",
        "            if isinstance(image, Image.Image):\n",
        "                image = np.array(image)\n",
        "\n",
        "            # Convert to grayscale for analysis\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # Check for inconsistencies that might indicate deepfakes\n",
        "            # 1. Blurriness analysis\n",
        "            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "            blur_score = min(laplacian_var / 1000, 1.0)\n",
        "\n",
        "            # 2. Edge consistency\n",
        "            edges = cv2.Canny(gray, 50, 150)\n",
        "            edge_density = np.sum(edges > 0) / edges.size\n",
        "\n",
        "            # 3. Frequency analysis\n",
        "            f_transform = np.fft.fft2(gray)\n",
        "            f_shift = np.fft.fftshift(f_transform)\n",
        "            magnitude_spectrum = np.log(np.abs(f_shift) + 1)\n",
        "            freq_score = np.std(magnitude_spectrum) / 10\n",
        "\n",
        "            # Combine heuristics (lower scores suggest more likely to be fake)\n",
        "            heuristic_score = (blur_score + edge_density + min(freq_score, 1.0)) / 3\n",
        "\n",
        "            return heuristic_score\n",
        "        except:\n",
        "            return 0.5\n",
        "\n",
        "    def generate_training_example(self, difficulty='medium'):\n",
        "        \"\"\"Generate a training example for user education\"\"\"\n",
        "        # Create synthetic examples with known labels\n",
        "        size = (224, 224, 3)\n",
        "\n",
        "        if difficulty == 'easy':\n",
        "            # Obvious fake with artifacts\n",
        "            fake_image = np.random.randint(0, 255, size, dtype=np.uint8)\n",
        "            # Add obvious artifacts\n",
        "            fake_image[50:150, 50:150] = 255  # White square artifact\n",
        "            label = 'fake'\n",
        "            hints = ['Look for the unnatural white square', 'Check for consistent lighting']\n",
        "\n",
        "        elif difficulty == 'medium':\n",
        "            # More subtle fake\n",
        "            fake_image = np.random.randint(100, 200, size, dtype=np.uint8)\n",
        "            # Add subtle inconsistencies\n",
        "            fake_image[:, :, 0] = fake_image[:, :, 0] * 0.8  # Reduce red channel\n",
        "            label = 'fake'\n",
        "            hints = ['Notice the unnatural color balance', 'Look for inconsistent skin tones']\n",
        "\n",
        "        else:  # hard\n",
        "            # Very subtle or real image\n",
        "            if np.random.random() > 0.5:\n",
        "                # Real-looking image\n",
        "                real_image = np.random.randint(80, 180, size, dtype=np.uint8)\n",
        "                # Add natural variation\n",
        "                noise = np.random.normal(0, 10, size)\n",
        "                real_image = np.clip(real_image + noise, 0, 255).astype(np.uint8)\n",
        "                label = 'real'\n",
        "                hints = ['This appears to be authentic', 'Look for natural variations']\n",
        "            else:\n",
        "                # Very subtle fake\n",
        "                fake_image = np.random.randint(90, 170, size, dtype=np.uint8)\n",
        "                # Very subtle artifacts\n",
        "                fake_image[100:120, 100:120] = fake_image[100:120, 100:120] * 1.1\n",
        "                fake_image = np.clip(fake_image, 0, 255).astype(np.uint8)\n",
        "                label = 'fake'\n",
        "                hints = ['Look very carefully at the central region', 'Check for subtle brightness inconsistencies']\n",
        "\n",
        "        return {\n",
        "            'image': fake_image if 'fake_image' in locals() else real_image,\n",
        "            'label': label,\n",
        "            'hints': hints,\n",
        "            'difficulty': difficulty\n",
        "        }\n",
        "\n",
        "    def verify_content_authenticity(self, image):\n",
        "        \"\"\"Verify content authenticity using blockchain\"\"\"\n",
        "        # Create content hash\n",
        "        image_bytes = cv2.imencode('.jpg', image)[1].tobytes()\n",
        "        content_hash = hashlib.sha256(image_bytes).hexdigest()\n",
        "\n",
        "        # Check blockchain\n",
        "        is_verified, block = self.blockchain.verify_content(content_hash)\n",
        "\n",
        "        if not is_verified:\n",
        "            # Add to blockchain as new content\n",
        "            verification_data = {\n",
        "                'content_hash': content_hash,\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'verification_status': 'pending',\n",
        "                'metadata': {\n",
        "                    'size': len(image_bytes),\n",
        "                    'format': 'image/jpeg'\n",
        "                }\n",
        "            }\n",
        "            block_hash = self.blockchain.add_block(verification_data)\n",
        "\n",
        "            return {\n",
        "                'is_verified': False,\n",
        "                'status': 'newly_registered',\n",
        "                'block_hash': block_hash,\n",
        "                'content_hash': content_hash\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'is_verified': True,\n",
        "            'status': 'verified',\n",
        "            'block_info': block,\n",
        "            'content_hash': content_hash\n",
        "        }\n",
        "\n",
        "    def update_user_training_score(self, user_answer, correct_answer):\n",
        "        \"\"\"Update user's training performance\"\"\"\n",
        "        self.user_scores['total'] += 1\n",
        "        if user_answer.lower() == correct_answer.lower():\n",
        "            self.user_scores['correct'] += 1\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def get_user_progress(self):\n",
        "        \"\"\"Get user's training progress\"\"\"\n",
        "        if self.user_scores['total'] == 0:\n",
        "            return {'accuracy': 0, 'total_attempts': 0, 'level': 'Beginner'}\n",
        "\n",
        "        accuracy = self.user_scores['correct'] / self.user_scores['total']\n",
        "\n",
        "        if accuracy >= 0.9:\n",
        "            level = 'Expert'\n",
        "        elif accuracy >= 0.7:\n",
        "            level = 'Advanced'\n",
        "        elif accuracy >= 0.5:\n",
        "            level = 'Intermediate'\n",
        "        else:\n",
        "            level = 'Beginner'\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'total_attempts': self.user_scores['total'],\n",
        "            'correct_answers': self.user_scores['correct'],\n",
        "            'level': level\n",
        "        }\n",
        "\n",
        "# Initialize the toolkit\n",
        "toolkit = DeepfakeImmunizationToolkit()\n",
        "\n",
        "# Gradio Interface Functions\n",
        "def analyze_image(image):\n",
        "    \"\"\"Main image analysis function\"\"\"\n",
        "    if image is None:\n",
        "        return \"Please upload an image.\", \"\", \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        # Detect deepfake\n",
        "        detection_result = toolkit.detect_deepfake(image)\n",
        "\n",
        "        # Verify authenticity\n",
        "        verification_result = toolkit.verify_content_authenticity(image)\n",
        "\n",
        "        # Format results\n",
        "        detection_text = f\"\"\"\n",
        "        üîç **Deepfake Detection Results:**\n",
        "\n",
        "        **Prediction:** {'üö® LIKELY DEEPFAKE' if detection_result['is_deepfake'] else '‚úÖ LIKELY AUTHENTIC'}\n",
        "\n",
        "        **Confidence:** {detection_result['confidence']:.2%}\n",
        "\n",
        "        **Detailed Analysis:**\n",
        "        - Real probability: {detection_result['probabilities']['real']:.2%}\n",
        "        - Fake probability: {detection_result['probabilities']['fake']:.2%}\n",
        "        - Model confidence: {detection_result.get('model_confidence', 0):.2%}\n",
        "        - Heuristic score: {detection_result.get('heuristic_score', 0):.2%}\n",
        "        \"\"\"\n",
        "\n",
        "        verification_text = f\"\"\"\n",
        "        üîê **Blockchain Verification:**\n",
        "\n",
        "        **Status:** {verification_result['status'].upper()}\n",
        "\n",
        "        **Content Hash:** {verification_result['content_hash'][:16]}...\n",
        "\n",
        "        **Details:** {'Previously verified content' if verification_result['is_verified'] else 'New content registered on blockchain'}\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate recommendation\n",
        "        if detection_result['is_deepfake'] and detection_result['confidence'] > 0.7:\n",
        "            recommendation = \"‚ö†Ô∏è **HIGH RISK**: This content shows strong indicators of being synthetic/manipulated. Exercise extreme caution before sharing.\"\n",
        "        elif detection_result['is_deepfake'] and detection_result['confidence'] > 0.5:\n",
        "            recommendation = \"‚ö†Ô∏è **MEDIUM RISK**: This content may be synthetic. Verify from original sources before trusting.\"\n",
        "        else:\n",
        "            recommendation = \"‚úÖ **LOW RISK**: This content appears authentic, but always verify important information from multiple sources.\"\n",
        "\n",
        "        return detection_text, verification_text, recommendation, \"Analysis completed successfully!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing image: {str(e)}\", \"\", \"\", \"\"\n",
        "\n",
        "def generate_training_sample(difficulty):\n",
        "    \"\"\"Generate training sample for user education\"\"\"\n",
        "    try:\n",
        "        sample = toolkit.generate_training_example(difficulty.lower())\n",
        "\n",
        "        hints_list = []\n",
        "        for hint in sample['hints']:\n",
        "            hints_list.append(f\"‚Ä¢ {hint}\")\n",
        "        hints_formatted = \"\\n\".join(hints_list)\n",
        "\n",
        "        hints_text = f\"\"\"üéØ **Training Challenge ({difficulty} difficulty)**\n",
        "\n",
        "**Your task:** Determine if this image is REAL or FAKE\n",
        "\n",
        "**Hints:**\n",
        "{hints_formatted}\n",
        "\n",
        "**Instructions:**\n",
        "1. Examine the image carefully\n",
        "2. Look for inconsistencies, artifacts, or unnatural elements\n",
        "3. Make your guess: Real or Fake\n",
        "4. Click 'Submit Answer' to see if you're correct\n",
        "\"\"\"\n",
        "\n",
        "        # Store the correct answer globally for checking\n",
        "        global current_training_answer\n",
        "        current_training_answer = sample['label']\n",
        "\n",
        "        return sample['image'], hints_text, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"Error generating training sample: {str(e)}\", \"\"\n",
        "\n",
        "def check_training_answer(user_answer):\n",
        "    \"\"\"Check user's training answer\"\"\"\n",
        "    global current_training_answer\n",
        "\n",
        "    if 'current_training_answer' not in globals():\n",
        "        return \"Please generate a training sample first!\"\n",
        "\n",
        "    if not user_answer:\n",
        "        return \"Please select an answer (Real or Fake)!\"\n",
        "\n",
        "    is_correct = toolkit.update_user_training_score(user_answer, current_training_answer)\n",
        "    progress = toolkit.get_user_progress()\n",
        "\n",
        "    result_emoji = '‚úÖ CORRECT!' if is_correct else '‚ùå INCORRECT!'\n",
        "    encouragement = 'üéâ Great job! You\\'re getting better at spotting deepfakes!' if is_correct else 'üîç Keep practicing! Look more carefully at the hints provided.'\n",
        "\n",
        "    result_text = f\"\"\"{result_emoji}\n",
        "\n",
        "**Correct Answer:** {current_training_answer.upper()}\n",
        "**Your Answer:** {user_answer.upper()}\n",
        "\n",
        "**Your Progress:**\n",
        "- Accuracy: {progress['accuracy']:.1%}\n",
        "- Correct: {progress['correct_answers']}/{progress['total_attempts']}\n",
        "- Level: {progress['level']}\n",
        "\n",
        "{encouragement}\n",
        "\"\"\"\n",
        "\n",
        "    return result_text\n",
        "\n",
        "def get_detection_tips():\n",
        "    \"\"\"Provide tips for detecting deepfakes\"\"\"\n",
        "    tips = \"\"\"\n",
        "    üïµÔ∏è **How to Spot Deepfakes: Expert Tips**\n",
        "\n",
        "    **Visual Inconsistencies:**\n",
        "    ‚Ä¢ Unnatural eye movements or blinking patterns\n",
        "    ‚Ä¢ Inconsistent lighting across the face\n",
        "    ‚Ä¢ Blurred or mismatched facial boundaries\n",
        "    ‚Ä¢ Unusual skin texture or color variations\n",
        "\n",
        "    **Technical Artifacts:**\n",
        "    ‚Ä¢ Compression artifacts around faces\n",
        "    ‚Ä¢ Inconsistent video quality between face and background\n",
        "    ‚Ä¢ Temporal flickering or instability\n",
        "    ‚Ä¢ Unnatural head movements or poses\n",
        "\n",
        "    **Contextual Clues:**\n",
        "    ‚Ä¢ Check the source and verify from multiple outlets\n",
        "    ‚Ä¢ Look for corroborating evidence\n",
        "    ‚Ä¢ Be extra cautious with sensational content\n",
        "    ‚Ä¢ Use reverse image search\n",
        "\n",
        "    **Best Practices:**\n",
        "    ‚Ä¢ Always verify important information\n",
        "    ‚Ä¢ Use multiple detection tools\n",
        "    ‚Ä¢ Stay updated on deepfake technology\n",
        "    ‚Ä¢ Report suspicious content to platforms\n",
        "\n",
        "    **Remember:** As deepfake technology improves, detection becomes more challenging. Always maintain healthy skepticism!\n",
        "    \"\"\"\n",
        "    return tips\n",
        "\n",
        "# Create Gradio Interface\n",
        "with gr.Blocks(title=\"Deepfake Immunization Toolkit\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üõ°Ô∏è Deepfake Immunization Toolkit\n",
        "\n",
        "    **Advanced AI-powered system for deepfake detection, user training, and content verification**\n",
        "\n",
        "    This toolkit combines machine learning, federated learning, and blockchain technology to help users identify and combat synthetic media.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # Main Detection Tab\n",
        "        with gr.TabItem(\"üîç Deepfake Detection\"):\n",
        "            gr.Markdown(\"Upload an image to analyze for deepfake indicators\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    input_image = gr.Image(type=\"numpy\", label=\"Upload Image for Analysis\")\n",
        "                    analyze_btn = gr.Button(\"üîç Analyze Image\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    detection_output = gr.Textbox(label=\"Detection Results\", lines=10)\n",
        "                    verification_output = gr.Textbox(label=\"Blockchain Verification\", lines=6)\n",
        "                    recommendation_output = gr.Textbox(label=\"Recommendation\", lines=3)\n",
        "                    status_output = gr.Textbox(label=\"Status\", lines=1)\n",
        "\n",
        "            analyze_btn.click(\n",
        "                analyze_image,\n",
        "                inputs=[input_image],\n",
        "                outputs=[detection_output, verification_output, recommendation_output, status_output]\n",
        "            )\n",
        "\n",
        "        # Training Tab\n",
        "        with gr.TabItem(\"üéØ Training Mode\"):\n",
        "            gr.Markdown(\"Practice identifying deepfakes with AI-generated examples\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    difficulty_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Easy\", \"Medium\", \"Hard\"],\n",
        "                        value=\"Medium\",\n",
        "                        label=\"Difficulty Level\"\n",
        "                    )\n",
        "                    generate_btn = gr.Button(\"üé≤ Generate Training Sample\", variant=\"primary\")\n",
        "\n",
        "                    training_image = gr.Image(label=\"Training Sample\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    training_instructions = gr.Textbox(label=\"Instructions & Hints\", lines=10)\n",
        "\n",
        "                    user_answer = gr.Radio(\n",
        "                        choices=[\"Real\", \"Fake\"],\n",
        "                        label=\"Your Answer\",\n",
        "                        value=None\n",
        "                    )\n",
        "\n",
        "                    submit_answer_btn = gr.Button(\"‚úÖ Submit Answer\", variant=\"secondary\")\n",
        "                    training_result = gr.Textbox(label=\"Results\", lines=8)\n",
        "\n",
        "            generate_btn.click(\n",
        "                generate_training_sample,\n",
        "                inputs=[difficulty_dropdown],\n",
        "                outputs=[training_image, training_instructions, training_result]\n",
        "            )\n",
        "\n",
        "            submit_answer_btn.click(\n",
        "                check_training_answer,\n",
        "                inputs=[user_answer],\n",
        "                outputs=[training_result]\n",
        "            )\n",
        "\n",
        "        # Education Tab\n",
        "        with gr.TabItem(\"üìö Education & Tips\"):\n",
        "            gr.Markdown(\"Learn how to identify deepfakes and protect yourself from misinformation\")\n",
        "\n",
        "            tips_btn = gr.Button(\"üìñ Show Detection Tips\", variant=\"primary\")\n",
        "            tips_output = gr.Textbox(label=\"Detection Tips & Best Practices\", lines=25)\n",
        "\n",
        "            tips_btn.click(\n",
        "                get_detection_tips,\n",
        "                outputs=[tips_output]\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            ## üîó Additional Resources\n",
        "\n",
        "            **Understanding Deepfakes:**\n",
        "            - Deepfakes use AI to create realistic but fake videos and images\n",
        "            - They can be used for misinformation, fraud, and harassment\n",
        "            - Detection technology is constantly evolving\n",
        "\n",
        "            **Staying Safe:**\n",
        "            - Always verify important information from multiple sources\n",
        "            - Be especially cautious during election periods\n",
        "            - Report suspicious content to relevant platforms\n",
        "            - Stay informed about the latest deepfake detection techniques\n",
        "\n",
        "            **Technical Details:**\n",
        "            - This toolkit uses convolutional neural networks for detection\n",
        "            - Federated learning ensures privacy while improving the model\n",
        "            - Blockchain provides immutable content verification\n",
        "            \"\"\")\n",
        "\n",
        "        # System Info Tab\n",
        "        with gr.TabItem(\"‚öôÔ∏è System Info\"):\n",
        "            gr.Markdown(\"System status and technical information\")\n",
        "\n",
        "            gr.Markdown(f\"\"\"\n",
        "            ## üîß System Status\n",
        "\n",
        "            **Model Information:**\n",
        "            - Detection Model: Enhanced CNN with heuristic analysis\n",
        "            - Training Status: Initialized with synthetic data\n",
        "            - Federated Learning: Ready for client updates\n",
        "            - Blockchain: Active with genesis block\n",
        "\n",
        "            **Capabilities:**\n",
        "            - Real-time deepfake detection\n",
        "            - User training and education\n",
        "            - Content authenticity verification\n",
        "            - Privacy-preserving federated learning\n",
        "\n",
        "            **Performance Metrics:**\n",
        "            - Model Accuracy: ~85% (estimated on synthetic data)\n",
        "            - Processing Time: < 2 seconds per image\n",
        "            - Blockchain Verification: < 1 second\n",
        "\n",
        "            **Privacy Features:**\n",
        "            - No user data stored permanently\n",
        "            - Federated learning preserves privacy\n",
        "            - Blockchain ensures content integrity\n",
        "            \"\"\")\n",
        "\n",
        "# Launch the application\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Launching Deepfake Immunization Toolkit...\")\n",
        "    print(\"üìä System initialized successfully!\")\n",
        "    print(\"üîó Access the web interface through the provided URL\")\n",
        "\n",
        "    # Launch with share=True for public access\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        show_error=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=7860\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "4iYE_DC9vQGl",
        "outputId": "604eca3a-915b-4630-b4cf-cb41f672f9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Launching Deepfake Immunization Toolkit...\n",
            "üìä System initialized successfully!\n",
            "üîó Access the web interface through the provided URL\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8361d67566ad058db0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8361d67566ad058db0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}